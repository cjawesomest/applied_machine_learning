{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('venv_tf')",
   "metadata": {
    "interpreter": {
     "hash": "2aede538084b1e921b9794415c4a0126ad67a262a507bf8f8ac559279713767f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create some values\n",
    "import numpy as np\n",
    "import keras\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10)) # wave 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5) # + noise\n",
    "    return series[..., np.newaxis].astype(np.float32)\n",
    "\n",
    "#And generate some data\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Naive Error: 0.020667411\n",
      "Epoch 1/30\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.0645 - val_loss: 0.0140\n",
      "Epoch 2/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 3/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 4/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 5/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 6/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 7/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 8/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 9/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 10/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 11/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 12/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 13/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 14/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 15/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 16/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 17/30\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 18/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 19/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 20/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 21/30\n",
      "219/219 [==============================] - 0s 999us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 22/30\n",
      "219/219 [==============================] - 0s 899us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 23/30\n",
      "219/219 [==============================] - 0s 917us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 24/30\n",
      "219/219 [==============================] - 0s 881us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 25/30\n",
      "219/219 [==============================] - 0s 876us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 26/30\n",
      "219/219 [==============================] - 0s 878us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 27/30\n",
      "219/219 [==============================] - 0s 884us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 28/30\n",
      "219/219 [==============================] - 0s 934us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 29/30\n",
      "219/219 [==============================] - 0s 886us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 30/30\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Naive Error: 0.0030650846\n"
     ]
    }
   ],
   "source": [
    "#Simple Naive Forecasting\n",
    "y_pred = X_valid[:, -1]\n",
    "print(\"Naive Error: \"+str(np.mean(keras.losses.mean_squared_error(y_valid, y_pred))))\n",
    "\n",
    "#Fully Connected Linear Regression Model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50, 1]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\",\n",
    "    optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "    validation_data=(X_valid, y_valid))\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Naive Error: \"+str(np.mean(keras.losses.mean_squared_error(y_pred, y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 3s 7ms/step - loss: 0.5346 - val_loss: 0.2854\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.2705 - val_loss: 0.2395\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.2208 - val_loss: 0.1976\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1800 - val_loss: 0.1614\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1500 - val_loss: 0.1458\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1352 - val_loss: 0.1392\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1395 - val_loss: 0.1448\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1392 - val_loss: 0.1385\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1399 - val_loss: 0.1413\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1348 - val_loss: 0.1419\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1377 - val_loss: 0.1393\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1378 - val_loss: 0.1388\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1363 - val_loss: 0.1384\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1346 - val_loss: 0.1388\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1347 - val_loss: 0.1394\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1382 - val_loss: 0.1386\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1391 - val_loss: 0.1417\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1363 - val_loss: 0.1412\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1397 - val_loss: 0.1388\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1387 - val_loss: 0.1391\n",
      "Simple RNN Error: 0.13466029\n"
     ]
    }
   ],
   "source": [
    "#Simple RNN (default htan activation)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])\n",
    "model.compile(loss=\"mse\",\n",
    "    optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "    validation_data=(X_valid, y_valid))\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Simple RNN Error: \"+str(np.mean(keras.losses.mean_squared_error(y_pred, y_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 6s 16ms/step - loss: 0.0869 - val_loss: 0.0083\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Deep RNN Error: 0.0032455935\n"
     ]
    }
   ],
   "source": [
    "#More layers, more complexity\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])\n",
    "model.compile(loss=\"mse\",\n",
    "    optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "    validation_data=(X_valid, y_valid))\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Deep RNN Error: \"+str(np.mean(keras.losses.mean_squared_error(y_pred, y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 5s 13ms/step - loss: 0.0428 - val_loss: 0.0038\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Deep RNN Dense Output Error: 0.002639518\n"
     ]
    }
   ],
   "source": [
    "#Replacing output with a Dense layer for customizable activation function\n",
    "#It's quicker too\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\",\n",
    "    optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "    validation_data=(X_valid, y_valid))\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Deep RNN Dense Output Error: \"+str(np.mean(keras.losses.mean_squared_error(y_pred, y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Future Predict RNN Error: 0.016024485\n"
     ]
    }
   ],
   "source": [
    "#Predicting farther aheaad than just one step\n",
    "#Same model, just add next prediction to input sequence\n",
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "\n",
    "Y_pred = X[:, n_steps:]\n",
    "print(\"Future Predict RNN Error: \"+str(np.mean(keras.losses.mean_squared_error(Y_pred, Y_new))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 5s 11ms/step - loss: 0.1707 - val_loss: 0.1442\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1461 - val_loss: 0.1433\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1442 - val_loss: 0.1433\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.1421 - val_loss: 0.1430\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.1445 - val_loss: 0.1429\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.1436 - val_loss: 0.1429\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.1405 - val_loss: 0.1431\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1421 - val_loss: 0.1431\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1414 - val_loss: 0.1431\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1430 - val_loss: 0.1429\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1418 - val_loss: 0.1429\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1438 - val_loss: 0.1431\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1477 - val_loss: 0.1430\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1449 - val_loss: 0.1431\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.1401 - val_loss: 0.1430\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1434 - val_loss: 0.1431\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1448 - val_loss: 0.1431\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1413 - val_loss: 0.1432\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1417 - val_loss: 0.1432\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.1423 - val_loss: 0.1433\n",
      "All at Once RNN Error: 0.12979983\n"
     ]
    }
   ],
   "source": [
    "#Predict all values at once!\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(loss=\"mse\",\n",
    "    optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "    validation_data=(X_valid, y_valid))\n",
    "Y_pred = model.predict(X_new)\n",
    "print(\"All at Once RNN Error: \"+str(np.mean(keras.losses.mean_squared_error(Y_pred, Y_new))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "219/219 [==============================] - 5s 13ms/step - loss: 0.0720 - last_time_step_mse: 0.0614 - val_loss: 0.0411 - val_last_time_step_mse: 0.0289\n",
      "Epoch 2/5\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0412 - last_time_step_mse: 0.0303 - val_loss: 0.0368 - val_last_time_step_mse: 0.0232\n",
      "Epoch 3/5\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0346 - last_time_step_mse: 0.0227 - val_loss: 0.0342 - val_last_time_step_mse: 0.0236\n",
      "Epoch 4/5\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0313 - last_time_step_mse: 0.0193 - val_loss: 0.0266 - val_last_time_step_mse: 0.0139\n",
      "Epoch 5/5\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0261 - last_time_step_mse: 0.0126 - val_loss: 0.0234 - val_last_time_step_mse: 0.0100\n"
     ]
    }
   ],
   "source": [
    "#Sequence to sequence model\n",
    "Y = np.empty((10000, n_steps, 10)) # each target is a sequence of 10D vectors\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[:, :, step_ahead - 1] = series[:, step_ahead:step_ahead + n_steps, 0]\n",
    "Y_train = Y[:7000]\n",
    "Y_valid = Y[7000:9000]\n",
    "Y_test = Y[9000:]\n",
    "\n",
    "#return_sequences=True\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "#Custom metric\n",
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=5,\n",
    "    validation_data=(X_valid, Y_valid))\n",
    "Y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer Normalization\n",
    "class LNSimpleRNNCell(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,\n",
    "        activation=None)\n",
    "        self.layer_norm = keras.layers.LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]\n",
    "\n",
    "#Regenerate data\n",
    "# n_steps = 50\n",
    "# series = generate_time_series(10000, n_steps + 1)\n",
    "# X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "# X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "# X_test, y_test = series[9000:, :n_steps], series[9000:, -1]\n",
    "\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,\n",
    "    input_shape=[None, 1]),\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "model.compile(loss=\"mse\",\n",
    "    optimizer=\"adam\")\n",
    "# history = model.fit(X_train, Y_train, epochs=20,\n",
    "#     validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM!\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "#OR\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True,\n",
    "    input_shape=[None, 1]),\n",
    "    keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "#Peephole (experimental)\n",
    "# tf.keras.experimental.PeepholeLSTMCell\n",
    "\n",
    "#Gated Recurrent Unit (GRUs)\n",
    "# keras.layers.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:755 train_step\n        loss = self.compiled_loss(\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1198 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:10249 squared_difference\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3528 _create_op_internal\n        ret = Operation(\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 10 and 4 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_25/time_distributed_14/Reshape_1, IteratorGetNext:1)' with input shapes: [?,24,10], [?,4].\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-5cfa88541e5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m ])\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mse\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlast_time_step_mse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m history = model.fit(X_train, Y_train[:, 3::2], epochs=20,\n\u001b[0m\u001b[0;32m     11\u001b[0m     validation_data=(X_valid, Y_valid[:, 3::2]))\n",
      "\u001b[1;32mj:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mj:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mj:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mj:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 725\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    726\u001b[0m             *args, **kwds))\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mj:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mj:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mj:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mj:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mj:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mj:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:755 train_step\n        loss = self.compiled_loss(\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1198 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:10249 squared_difference\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3528 _create_op_internal\n        ret = Operation(\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    j:\\School Files\\[In progress] ECE612 Applied Machine Learning\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 10 and 4 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_25/time_distributed_14/Reshape_1, IteratorGetNext:1)' with input shapes: [?,24,10], [?,4].\n"
     ]
    }
   ],
   "source": [
    "#1D Convlutional Layers for Sequences\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\",\n",
    "    input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "# history = model.fit(X_train, Y_train[:, 3::2], epochs=20,\n",
    "#     validation_data=(X_valid, Y_valid[:, 3::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WaveNet\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
    "for rate in (1, 2, 4, 8) * 2:\n",
    "    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=\"causal\",\n",
    "        activation=\"relu\", dilation_rate=rate))\n",
    "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "# history = model.fit(X_train, Y_train, epochs=20,\n",
    "#     validation_data=(X_valid, Y_valid))"
   ]
  }
 ]
}